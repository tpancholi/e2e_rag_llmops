embedding_model:
  google:
    provider: "google"
    model_name: "gemini-embedding-001"
  openai:
    provider: "openai"
    model_name: "text-embedding-3-small"

retriever:
  top_k: 10
  search_type: "mmr" # MMR (Maximal Marginal Relevance) parameters for diverse results
  fetch_k: 50  # Number of documents to fetch before MMR re-ranking (should be > top_k)
  lambda_mult: 0.5  # Diversity vs. relevance (0=max diversity, 1=max relevance)

llm_model:
  groq:
    provider: "groq"
    model_name: "openai/gpt-oss-20b"
    temperature: 0.0
    max_output_tokens: 2048

  google:
    provider: "google"
    model_name: "gemini-2.5-flash-lite"
    temperature: 0.0
    max_output_tokens: 2048

  openai:
    provider: "openai"
    model_name: "gpt-5-mini"
    temperature: 0.0
    max_output_tokens: 2048
